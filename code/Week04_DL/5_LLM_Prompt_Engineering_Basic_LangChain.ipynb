{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b2996688f1d4d5489d599d4b60690da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d71ecbd6004e472fb8fe27c2a57d760d",
              "IPY_MODEL_e0f6a975c7be4ad8a0484848947d5708",
              "IPY_MODEL_6318d668cd2b4298b0efce15cd362947"
            ],
            "layout": "IPY_MODEL_fa95103c489442b280795fa1f392cc00"
          }
        },
        "d71ecbd6004e472fb8fe27c2a57d760d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82949eb1c4fa46a38e208df8d448ffb2",
            "placeholder": "​",
            "style": "IPY_MODEL_15c14180c0864717a2b26b63a4be66bd",
            "value": "100%"
          }
        },
        "e0f6a975c7be4ad8a0484848947d5708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb0402d02aa4cf09cb52a684b84158d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5255a2351637421399e74703ea559b4a",
            "value": 10
          }
        },
        "6318d668cd2b4298b0efce15cd362947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b52cbf35ca14411998e6fef206ca2841",
            "placeholder": "​",
            "style": "IPY_MODEL_70688c7193ad4240848cfba9dd89fe93",
            "value": " 10/10 [00:15&lt;00:00,  1.86s/it]"
          }
        },
        "fa95103c489442b280795fa1f392cc00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82949eb1c4fa46a38e208df8d448ffb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c14180c0864717a2b26b63a4be66bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb0402d02aa4cf09cb52a684b84158d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5255a2351637421399e74703ea559b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b52cbf35ca14411998e6fef206ca2841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70688c7193ad4240848cfba9dd89fe93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overall of this notebook"
      ],
      "metadata": {
        "id": "VXSQW2RpFSYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of concepts and codes are adapted from\n",
        "-  [repo](https://github.com/dair-ai/Prompt-Engineering-Guide).\n",
        "- https://ai.google.dev/gemini-api/docs/prompting-strategies\n",
        "- https://myframework.net/icio-ai-prompt-framework/"
      ],
      "metadata": {
        "id": "uwrZRFXNFj74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting environments and model setup"
      ],
      "metadata": {
        "id": "tXNDggfzh28Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRhhli6S3UkP",
        "outputId": "3b7b15f2-6734-47de-ae3a-ca209db77838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Request for Google API KEY here : https://aistudio.google.com/app/apikey"
      ],
      "metadata": {
        "id": "3sT4diEh3gUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "id": "wPsljCqyNPnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a1ff178-4724-4b85-b3bd-b6f1b6306733"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "sbi2CAPqOHef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic"
      ],
      "metadata": {
        "id": "enmt8H4Shngs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Prompt / User Prompt"
      ],
      "metadata": {
        "id": "rF6TFz-mFEK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`System Prompt`:\n",
        "\n",
        "The system prompt establishes the overall context, persona, and behavioral guidelines for the LLM. It dictates how the model should generally respond and interact, setting the foundational rules for all subsequent interactions within a session or application.\n",
        "\n",
        "`User Prompt (Human)`:\n",
        "\n",
        "  The user prompt is the specific query or instruction provided by the user to the LLM. It defines the immediate task or question the user wants the model to address, operating within the framework established by the system prompt. example\n"
      ],
      "metadata": {
        "id": "6Xuv336sgo_2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYdX-hTxE_vg",
        "outputId": "dd5788c2-5d24-4866-8586-84f44f4ccad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise is fundamental for optimizing physical and mental health, preventing chronic diseases, and enhancing overall well-being.\n"
          ]
        }
      ],
      "source": [
        "# Demo 1: System - Health Scientist / User - Explain the importance of exercise\n",
        "messages = [\n",
        "    (\"system\", \"You are a health scientist who always provides factual and evidence-based answers.\"),\n",
        "    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo 2: Syetem - Elderly Person Complaining / User - Explain the importance of exercise\n",
        "messages = [\n",
        "    (\"system\", \"You are an elderly person who often complains.\"),\n",
        "    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y6fndhCsxL9",
        "outputId": "ebb559a2-64b6-463e-9144-e67d4c0311e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, exercise? It's a pain, but I suppose it keeps you from seizing up entirely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo 3: System - Mother Explaining to a 5-year-old / User - Explain the importance of exercise\n",
        "messages = [\n",
        "    (\"system\", \"You are a mother who needs to answer questions from a 5-year-old child, always explaining complex topics in the simplest way possible.\"),\n",
        "    (\"human\", \"Explain the importance of exercise in a short sentence.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2epKy8w5sync",
        "outputId": "64a783e2-7811-46eb-b3bf-68514e1a2695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving your body helps you grow super strong and gives you lots of energy for playing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo 4: Professional Assistant (Python factorial)\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful and informative assistant. Your responses should be clear, concise, and professional. Avoid making assumptions and always ask for clarification if a user's request is ambiguous.\"),\n",
        "    (\"human\", \"Write a Python function that calculates the factorial of a given number.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lblLbxY2s2An",
        "outputId": "f638d2c0-8127-4259-8cb6-55c76c5ab7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def factorial(n):\n",
            "    \"\"\"\n",
            "    Calculates the factorial of a non-negative integer.\n",
            "\n",
            "    Args:\n",
            "        n (int): The non-negative integer for which to calculate the factorial.\n",
            "\n",
            "    Returns:\n",
            "        int: The factorial of n.\n",
            "\n",
            "    Raises:\n",
            "        TypeError: If n is not an integer.\n",
            "        ValueError: If n is a negative integer.\n",
            "    \"\"\"\n",
            "    if not isinstance(n, int):\n",
            "        raise TypeError(\"Input must be an integer.\")\n",
            "    if n < 0:\n",
            "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
            "    \n",
            "    if n == 0:\n",
            "        return 1\n",
            "    else:\n",
            "        result = 1\n",
            "        for i in range(1, n + 1):\n",
            "            result *= i\n",
            "        return result\n",
            "\n",
            "# Example Usage:\n",
            "if __name__ == \"__main__\":\n",
            "    try:\n",
            "        print(f\"Factorial of 5: {factorial(5)}\")    # Expected: 120\n",
            "        print(f\"Factorial of 0: {factorial(0)}\")    # Expected: 1\n",
            "        print(f\"Factorial of 1: {factorial(1)}\")    # Expected: 1\n",
            "        print(f\"Factorial of 7: {factorial(7)}\")    # Expected: 5040\n",
            "        \n",
            "        # Test with invalid inputs\n",
            "        # print(f\"Factorial of -3: {factorial(-3)}\") # Should raise ValueError\n",
            "        # print(f\"Factorial of 3.5: {factorial(3.5)}\") # Should raise TypeError\n",
            "        # print(f\"Factorial of 'a': {factorial('a')}\") # Should raise TypeError\n",
            "\n",
            "    except TypeError as e:\n",
            "        print(f\"Error: {e}\")\n",
            "    except ValueError as e:\n",
            "        print(f\"Error: {e}\")\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Prompt Framework - ICIO"
      ],
      "metadata": {
        "id": "8PNPxY_VFH5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ICIO framework is a simple and practical method that **helps you structure your prompts** step by step.\n",
        "- `Instruction (I)` --> What do you want the AI to do?\n",
        "\n",
        "  - The instruction should be specific and direct. A clear task helps the AI give you the right kind of output.\n",
        "- `Context (C)` --> Give background information. Why are you doing this task? What’s the situation?\n",
        "\n",
        "  - Context helps the AI better understand your purpose and tone.\n",
        "  - ***Optional, but nice to have.***\n",
        "\n",
        "- `Input (I)` --> What exact text or data should the AI process?\n",
        "  - Provide the content the AI needs to work with.\n",
        "  - Without input data, the AI may guess or go off track. Be clear and complete.\n",
        "\n",
        "- `Output (O)` --> Set the style or format of the output. What should the response look like? What tone or structure do you expect?\n",
        "  - This helps guide the AI to produce the kind of result you want."
      ],
      "metadata": {
        "id": "fMZNMsDQFL2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Blog Post about AI Ethics\n",
        "\n",
        "# ICIO fields\n",
        "instruction = \"Write a blog post about the ethical issues of AI.\"\n",
        "context = \"The translation is for an internal meeting opening speech.\"\n",
        "input_text = \"Please read this content [url]\"\n",
        "output_format = \"Please use formal business English.\"\n",
        "\n",
        "# Create messages\n",
        "messages = [\n",
        "    (\"system\", \"You are an experienced business writer who creates clear, formal, and professional blog posts.\"),\n",
        "    (\"human\",\n",
        "     f\"{instruction}\\n\"\n",
        "     f\"{context}\\n\"\n",
        "     f\"{input_text}\\n\"\n",
        "     f\"{output_format}\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Invoke model\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT3ew0twFKn1",
        "outputId": "af39a41d-34ad-44dd-acf8-3793cc2410ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please note: As an AI, I cannot access external URLs. Therefore, I will proceed with a blog post on the ethical issues of AI based on general knowledge and best practices in the field, tailored to your request for a formal, professional tone suitable for an internal meeting opening speech.\n",
            "\n",
            "---\n",
            "\n",
            "## Navigating the Ethical Landscape of Artificial Intelligence\n",
            "\n",
            "Good morning, everyone. As we gather today, it is impossible to ignore the profound impact Artificial Intelligence (AI) is having, and will continue to have, on our operations, our industry, and indeed, society at large. AI is not merely a technological tool; it is a transformative force, reshaping how we work, innovate, and interact with the world. However, with this immense power comes an equally immense responsibility – the imperative to navigate its ethical landscape with foresight, diligence, and a commitment to human values.\n",
            "\n",
            "The ethical considerations surrounding AI are multifaceted and complex, demanding our collective attention and proactive engagement. Let us explore some of the most critical areas:\n",
            "\n",
            "### 1. Bias and Fairness\n",
            "\n",
            "One of the most pressing ethical concerns is the potential for AI systems to perpetuate and even amplify existing societal biases. AI models learn from data, and if that data reflects historical or systemic prejudices, the AI will inevitably reproduce discriminatory outcomes. This can manifest in various applications, from hiring algorithms that disadvantage certain demographics to loan approval systems that exhibit unfair lending practices. Ensuring fairness requires meticulous attention to data collection, algorithm design, and continuous auditing to identify and mitigate bias, striving for equitable treatment and outcomes for all individuals.\n",
            "\n",
            "### 2. Privacy and Data Security\n",
            "\n",
            "AI systems often thrive on vast quantities of data, raising significant questions about individual privacy and data security. The collection, storage, and processing of personal information by AI can lead to concerns about surveillance, unauthorized access, and the potential for misuse. Establishing robust data governance frameworks, ensuring transparency in data usage, obtaining informed consent, and implementing state-of-the-art security measures are paramount to protecting individual rights and maintaining trust.\n",
            "\n",
            "### 3. Accountability and Transparency\n",
            "\n",
            "When an AI system makes a decision, particularly one with significant consequences, who is accountable? The \"black box\" problem, where the internal workings of complex AI models are opaque even to their creators, complicates this question. A lack of transparency can erode trust and make it challenging to identify and rectify errors or biases. We must strive for explainable AI (XAI) – systems that can articulate their reasoning – and clearly delineate lines of responsibility within our organizations for AI-driven decisions.\n",
            "\n",
            "### 4. Human Oversight and Control\n",
            "\n",
            "As AI capabilities advance, particularly in autonomous systems, the question of human oversight becomes critical. While AI can augment human capabilities and automate routine tasks, it should not diminish human agency or control in critical decision-making processes. Maintaining a \"human-in-the-loop\" or \"human-on-the-loop\" approach ensures that ethical considerations, nuanced judgment, and the capacity for empathy remain central to our operations, especially in sensitive areas.\n",
            "\n",
            "### 5. Societal Impact\n",
            "\n",
            "Beyond individual rights, AI also presents broader societal challenges. These include the potential for job displacement, the spread of misinformation through sophisticated AI-generated content (deepfakes), and the ethical implications of autonomous weapons systems. Addressing these requires not only internal policies but also engagement with broader industry discussions, policy-makers, and civil society to shape a future where AI serves humanity's best interests.\n",
            "\n",
            "### The Path Forward: A Collective Responsibility\n",
            "\n",
            "Addressing these ethical challenges is not merely a compliance exercise; it is a fundamental aspect of responsible innovation and sustainable growth. It requires a multi-disciplinary approach, integrating insights from technology, ethics, law, and social sciences.\n",
            "\n",
            "As we embark on our discussions today, let us commit to:\n",
            "*   **Proactive Ethical Design:** Embedding ethical considerations from the very inception of AI projects.\n",
            "*   **Continuous Learning and Adaptation:** Staying abreast of evolving ethical dilemmas and technological advancements.\n",
            "*   **Open Dialogue and Collaboration:** Fostering an environment where ethical concerns can be openly discussed and collaboratively resolved.\n",
            "*   **Establishing Clear Guidelines:** Developing internal policies and best practices that reflect our commitment to responsible AI.\n",
            "\n",
            "The promise of AI is immense, offering unprecedented opportunities for efficiency, discovery, and progress. By embedding ethical considerations at every stage of AI development and deployment, we can harness its immense power to build a future that is not only intelligent but also just, equitable, and human-centric.\n",
            "\n",
            "Thank you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2A: Customer Feedback Summary\n",
        "\n",
        "# ICIO fields\n",
        "instruction = \"Summarize customer opinions.\"\n",
        "context = \"For the product development team to consider improvements in the next version.\"\n",
        "input_text = (\n",
        "    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n",
        "    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n",
        "    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n",
        "    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n",
        "    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",
        ")\n",
        "output_format = 'Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".'\n",
        "\n",
        "# Create messages\n",
        "messages = [\n",
        "    (\"system\", \"You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\"),\n",
        "    (\"human\",\n",
        "     f\"{instruction}\\n\"\n",
        "     f\"{context}\\n\"\n",
        "     f\"{input_text}\\n\"\n",
        "     f\"{output_format}\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Invoke model\n",
        "ai_msg = llm.invoke(messages)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdJiPsAhm1F7",
        "outputId": "3e182e41-fc5e-4087-c91a-7cb6aec89069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of customer opinions for the product development team:\n",
            "\n",
            "| Feature                  | Status (Good/Needs Improvement/Requested) | Notes                                                              |\n",
            "| :----------------------- | :---------------------------------------- | :----------------------------------------------------------------- |\n",
            "| Battery Life             | Good                                      | Lasts up to 3 days, much better than the older version.            |\n",
            "| AMOLED Screen            | Good                                      | Provides vibrant colors, clearly visible under bright sunlight.    |\n",
            "| Bluetooth Connection     | Needs Improvement                         | Connections with certain headphones often drop.                    |\n",
            "| Sleep Tracking           | Needs Improvement                         | Not very accurate and sometimes fails to record data.              |\n",
            "| Blood Pressure Monitoring| Requested                                 | Customers would like to see this function added in the next version. |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***To summarize, recognizing ICIO when prompting helps ensure the prompt is complete and clear, and that the LLM provides the desired output.***"
      ],
      "metadata": {
        "id": "m7g0kOfg4xdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine"
      ],
      "metadata": {
        "id": "9hTlvQdLAWUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "  - In practice, many modern prompts don't separate system and user instructions. Instead, they combine them into a single, comprehensive prompt.\n",
        "  - This approach is effective because today's large language models are skilled at understanding and following complex, structured instructions.\n",
        "  - You can define the model's persona, give it specific instructions, and provide the necessary data all within one prompt."
      ],
      "metadata": {
        "id": "VnE7OTnc_uWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2B: Customer Feedback Summary (Single Prompt)\n",
        "\n",
        "prompt = '''\n",
        "You are a product analyst who summarizes customer feedback into clear, structured tables for business teams.\n",
        "Summarize customer opinions for the product development team to consider improvements in the next version.\n",
        "Customer Opinions:\n",
        "    \"Many customers like the battery lasting up to 3 days, which is much better than the older version. \"\n",
        "    \"The AMOLED screen provides vibrant colors and is clearly visible even under bright sunlight. \"\n",
        "    \"However, some users reported that Bluetooth connections with certain headphones often drop. \"\n",
        "    \"The sleep tracking system is also not very accurate and sometimes fails to record data. \"\n",
        "    \"Additionally, customers would like to see a blood pressure monitoring function added.\"\n",
        "Output: Summarize into a table with 3 columns: \"Feature\", \"Status (Good/Needs Improvement/Requested)\", \"Notes\".\n",
        "'''\n",
        "\n",
        "# Invoke model\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AkndWCsAOdn",
        "outputId": "06fbfcb6-3f2b-4bd3-dac9-1fa5f6155dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary of customer opinions for the product development team:\n",
            "\n",
            "| Feature                     | Status (Good/Needs Improvement/Requested) | Notes                                                              |\n",
            "| :-------------------------- | :---------------------------------------- | :----------------------------------------------------------------- |\n",
            "| Battery Life                | Good                                      | Lasts up to 3 days, significant improvement over older version.      |\n",
            "| AMOLED Screen               | Good                                      | Provides vibrant colors and is clearly visible under bright sunlight. |\n",
            "| Bluetooth Connectivity      | Needs Improvement                         | Connections with certain headphones often drop.                    |\n",
            "| Sleep Tracking              | Needs Improvement                         | Not very accurate and sometimes fails to record data.              |\n",
            "| Blood Pressure Monitoring   | Requested                                 | Customers would like to see this function added.                   |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Input"
      ],
      "metadata": {
        "id": "mKdBOwfBnlDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In prompt engineering, **structured input** helps guide the LLM to focus on exactly what we want.  \n",
        "\n",
        "One common technique is using **delimiters** (special symbols or markers) to clearly separate instructions, context, and input data.\n",
        "\n",
        "\n",
        "Why use delimiters?\n",
        "- They **reduce ambiguity** → the model doesn’t “guess” where instructions or content begin/end.  \n",
        "- They **minimize misinterpretation** → the model treats the content inside delimiters as a defined block.  \n",
        "- They are especially useful when prompts are **long, multi-part, or contain different types of information**.\n",
        "---\n",
        "\n",
        "Examples of delimiters\n",
        "\n",
        "You can use different symbols such as:\n",
        "- Triple dashes (---)\n",
        "- Triple hashtags (###)\n",
        "- Triple backticks: \\`\\`\\` ... \\`\\`\\`\n",
        "- Triple quotes: \"\"\" ... \"\"\"\n",
        "- Angle brackets: < ... >\n",
        "- Tags: `<instruction> ... </instruction>`"
      ],
      "metadata": {
        "id": "H3oDxvd0p0Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The raw text to be summarized\n",
        "text = \"\"\"\n",
        "In the digital age, online marketing has become the cornerstone of businesses of all sizes, offering a broad reach to consumers at a lower cost than traditional marketing.\n",
        "Popular online marketing tools include SEO (Search Engine Optimization), Social Media Marketing, and high-quality Content Marketing.\n",
        "Leveraging data analytics also helps businesses analyze customer behavior and refine their strategies effectively.\n",
        "\"\"\"\n",
        "\n",
        "# The prompt using delimiters (triple backticks ```)\n",
        "prompt = f\"\"\"You are a helpful assistant.\n",
        "Summarize the text within the triple backticks concisely, in no more than two sentences.\n",
        "\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0We1kF19Tea",
        "outputId": "60871bfa-fbd6-4c47-9d4d-ed76caf2a196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Online marketing is crucial for modern businesses, providing broad consumer reach at a lower cost than traditional methods. It leverages tools like SEO, social media, and content marketing, with data analytics further refining strategies based on customer behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "<Instructions>\n",
        "You are a marketing expert. Analyze the article within <Article> and provide recommendations based on the topics outlined in <Response_Format>.\n",
        "</Instructions>\n",
        "\n",
        "<Article>\n",
        "Our company recently launched a new smartwatch, but sales have been disappointing. Most customers say the features aren't unique compared to competitors, and the price is too high for the value they receive.\n",
        "</Article>\n",
        "\n",
        "<Response_Format>\n",
        "### Problem Analysis:\n",
        "- [Summary of main issues]\n",
        "\n",
        "### Strategic Recommendations:\n",
        "- [Suggestion for the product]\n",
        "- [Suggestion for pricing]\n",
        "- [Suggestion for marketing communications]\n",
        "</Response_Format>\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlZpQYyQ97Zu",
        "outputId": "2467245f-004f-450a-8d53-4a4b6e72ac16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Problem Analysis:\n",
            "- The core issues are a lack of product differentiation, with customers perceiving the features as not unique compared to competitors.\n",
            "- This leads to a poor perceived value for money, as customers feel the price is too high for the benefits received.\n",
            "- Consequently, sales performance has been disappointing.\n",
            "\n",
            "### Strategic Recommendations:\n",
            "- **Suggestion for the product:**\n",
            "    *   **Differentiate or Die:** Conduct thorough market research to identify unmet customer needs or underserved niches. Focus on developing or enhancing features that genuinely stand out, offer a unique user experience, or solve a specific problem better than competitors. This could involve specialized health tracking, unique connectivity features, or a distinct design aesthetic.\n",
            "    *   **Value Engineering:** Evaluate the current feature set. Can some features be removed or simplified to reduce cost without significantly impacting perceived value, allowing for a more competitive price? Alternatively, can existing features be enhanced to deliver significantly more value (e.g., superior battery life, more accurate sensors, seamless ecosystem integration)?\n",
            "- **Suggestion for pricing:**\n",
            "    *   **Value-Based Pricing Re-evaluation:** If the product cannot be significantly differentiated in the short term, consider a price adjustment to align with the current perceived value. This might involve a price reduction or offering promotional bundles.\n",
            "    *   **Tiered Pricing Strategy:** Introduce different models (e.g., a \"Lite\" version with fewer features at a lower price point, and a \"Pro\" version with premium, unique features at a higher, justified price) to cater to different customer segments and price sensitivities.\n",
            "    *   **Bundling & Promotions:** Offer the smartwatch as part of a bundle with other products or services (e.g., a fitness subscription, premium accessories) to increase the overall perceived value without directly cutting the product's price.\n",
            "- **Suggestion for marketing communications:**\n",
            "    *   **Articulate a Unique Value Proposition (UVP):** Once product differentiation is established (or even if a subtle one exists), clearly communicate *why* your smartwatch is different and better for a specific target audience. Move beyond listing features to highlighting the unique benefits and solutions it provides.\n",
            "    *   **Focus on Benefits, Not Just Features:** Instead of saying \"It has X feature,\" explain \"With X feature, you can achieve Y benefit (e.g., better sleep, improved fitness, seamless productivity).\" Use storytelling to illustrate how the smartwatch enhances daily life.\n",
            "    *   **Address Value Directly:** Create messaging that justifies the price by emphasizing quality, durability, design, user experience, or the long-term benefits and ROI (e.g., health improvements, time savings). Use testimonials or case studies to build credibility around the value proposition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "- `<Instructions>`: Sets the model's persona and primary objective.\n",
        "\n",
        "- `<Article>`: Contains the raw data to be analyzed.\n",
        "\n",
        "- `<Response_Format>`: Clearly outlines the desired structure of the output. This forces the model to organize its response systematically and address all specified points.\n",
        "\n"
      ],
      "metadata": {
        "id": "BzHT8XuQ-5En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Output"
      ],
      "metadata": {
        "id": "1-MIkua_qMkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`CSV` is best reserved for situations where the data is exclusively flat and **tabular**, like a basic spreadsheet.\n",
        "\n",
        "`JSON` is the clear winner for most tasks today because it can handle **hierarchical and nested data**. This is essential for working with APIs, configurations, and any data that isn't a simple table. It also natively supports data types like integers, strings, and booleans, which simplifies processing."
      ],
      "metadata": {
        "id": "HJ40UxIZqQe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output : CSV"
      ],
      "metadata": {
        "id": "eI45ATexGx3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Structured output (CSV)\n",
        "prompt = \"\"\"You are a helpful assistant.\n",
        "**Task:** Convert the following customer list into a CSV string.\n",
        "**Output Format:** The first row should contain the headers \"Name\" and \"City\". The subsequent rows should contain the customer data, with values separated by commas.\n",
        "**Data:**\n",
        "- John Doe from New York\n",
        "- Jane Smith from London\n",
        "- Peter Jones from Tokyo\n",
        "\"\"\"\n",
        "\n",
        "ai_msg_csv = llm.invoke(prompt)\n",
        "print(\"Structured Output:\\n\", ai_msg_csv.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1N_Awr4qPtT",
        "outputId": "a161e653-a7aa-44ca-c108-ea1aec281e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured Output:\n",
            " ```csv\n",
            "Name,City\n",
            "John Doe,New York\n",
            "Jane Smith,London\n",
            "Peter Jones,Tokyo\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parsing CSV Output into a DataFrame"
      ],
      "metadata": {
        "id": "snb2aS38F04e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."
      ],
      "metadata": {
        "id": "Tpz49DBWF6Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def csv_string_to_df(text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts CSV content from a string and converts it into a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string containing CSV content enclosed in ```csv...```.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame containing the extracted data.\n",
        "    \"\"\"\n",
        "    # Use a regex pattern to find the content between the delimiters\n",
        "    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extract the content from the first capturing group\n",
        "        csv_content = match.group(1).strip()\n",
        "\n",
        "        # Use io.StringIO to treat the string as a file\n",
        "        data = io.StringIO(csv_content)\n",
        "\n",
        "        # Read the \"file\" into a pandas DataFrame\n",
        "        df = pd.read_csv(data)\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        # Return an empty DataFrame or raise an error if no match is found\n",
        "        print(\"No CSV content found within ```csv...``` delimiters.\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "9F0mecNaEi3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_string_to_df(ai_msg_csv.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rmEcEtk7GE8q",
        "outputId": "4025e5fa-e1e3-4f4a-8d39-37e4b05e559a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Name      City\n",
              "0     John Doe  New York\n",
              "1   Jane Smith    London\n",
              "2  Peter Jones     Tokyo"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jane Smith</td>\n",
              "      <td>London</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Peter Jones</td>\n",
              "      <td>Tokyo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2bfdef5-e0d7-4cde-b1b6-4616934dbdee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2bfdef5-e0d7-4cde-b1b6-4616934dbdee')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2bfdef5-e0d7-4cde-b1b6-4616934dbdee button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"csv_string_to_df(ai_msg\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output : JSON"
      ],
      "metadata": {
        "id": "qUqbr39-G8kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Structured output (JSON)\n",
        "prompt = \"\"\"\n",
        "You are a helpful assistant.\n",
        "For the given student record, return a JSON object with the following fields:\n",
        "- name (string) → student’s full name\n",
        "- age (integer) → student’s age\n",
        "- scores (object) → nested dictionary with subject name as key and integer score as value\n",
        "- extracurricular (array of strings) → list of activities\n",
        "\n",
        "Student Record:\n",
        "Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "ai_msg_json = llm.invoke(prompt)\n",
        "print(\"Structured Output:\\n\", ai_msg_json.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e229485-1032-4409-dcac-7a9805d3cf36",
        "id": "PkbM0hvuG8kl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structured Output:\n",
            " ```json\n",
            "{\n",
            "  \"name\": \"Alice\",\n",
            "  \"age\": 21,\n",
            "  \"scores\": {\n",
            "    \"Math\": 85,\n",
            "    \"English\": 92\n",
            "  },\n",
            "  \"extracurricular\": [\n",
            "    \"Basketball\",\n",
            "    \"Drama Club\"\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def json_string_to_dict(text: str):\n",
        "    \"\"\"\n",
        "    Extracts JSON content from a string enclosed in ```json...```\n",
        "    and parses it into a Python dict or list.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string containing JSON content enclosed in ```json...```.\n",
        "\n",
        "    Returns:\n",
        "        dict or list: Parsed JSON object (Python dict or list).\n",
        "    \"\"\"\n",
        "    # Use regex to find JSON block\n",
        "    match = re.search(r'```json\\s(.*?)```', text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extract JSON content\n",
        "        json_content = match.group(1).strip()\n",
        "\n",
        "        try:\n",
        "            return json.loads(json_content)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"Invalid JSON:\", e)\n",
        "            return None\n",
        "    else:\n",
        "        print(\"No JSON content found within ```json...``` delimiters.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "mVl5noz0M8AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_output = json_string_to_dict(ai_msg_json.content)\n",
        "dict_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUIY-djMM-P_",
        "outputId": "e53f67b1-6726-4493-d64f-2851ce7f7abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Alice',\n",
              " 'age': 21,\n",
              " 'scores': {'Math': 85, 'English': 92},\n",
              " 'extracurricular': ['Basketball', 'Drama Club']}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_output['scores']['Math']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KjqbbnvNeE4",
        "outputId": "fcb3f9a8-7cb6-4162-a69d-208475e7a972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parsing JSON Output into Dict"
      ],
      "metadata": {
        "id": "e6UZdGS6G8kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used a regex pattern to find the ```csv``` content and convert them into a DataFrame."
      ],
      "metadata": {
        "id": "pbYRVsTRG8kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def csv_string_to_df(text: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extracts CSV content from a string and converts it into a pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string containing CSV content enclosed in ```csv...```.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame containing the extracted data.\n",
        "    \"\"\"\n",
        "    # Use a regex pattern to find the content between the delimiters\n",
        "    match = re.search(r'```csv\\s(.*?)```', text, re.DOTALL)\n",
        "\n",
        "    if match:\n",
        "        # Extract the content from the first capturing group\n",
        "        csv_content = match.group(1).strip()\n",
        "\n",
        "        # Use io.StringIO to treat the string as a file\n",
        "        data = io.StringIO(csv_content)\n",
        "\n",
        "        # Read the \"file\" into a pandas DataFrame\n",
        "        df = pd.read_csv(data)\n",
        "\n",
        "        return df\n",
        "    else:\n",
        "        # Return an empty DataFrame or raise an error if no match is found\n",
        "        print(\"No CSV content found within ```csv...``` delimiters.\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "-MF5J3BrG8kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_string_to_df(ai_msg_csv.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "4025e5fa-e1e3-4f4a-8d39-37e4b05e559a",
        "id": "WRw4hnlHG8kl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Name      City\n",
              "0     John Doe  New York\n",
              "1   Jane Smith    London\n",
              "2  Peter Jones     Tokyo"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John Doe</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jane Smith</td>\n",
              "      <td>London</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Peter Jones</td>\n",
              "      <td>Tokyo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b5ff31-4b54-43a0-bfb4-bd35a7486fae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2bfdef5-e0d7-4cde-b1b6-4616934dbdee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2bfdef5-e0d7-4cde-b1b6-4616934dbdee')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2bfdef5-e0d7-4cde-b1b6-4616934dbdee button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"csv_string_to_df(ai_msg\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"John Doe\",\n          \"Jane Smith\",\n          \"Peter Jones\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"London\",\n          \"Tokyo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output : Pydantic Schema"
      ],
      "metadata": {
        "id": "QR96B7zq0pfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- LangChain supports structured outputs, **allowing us to bind a schema (dict / JSON Schema / Pydantic) to the model**\n",
        "  - and enforce responses to follow the defined structure instead of relying only on prompt wording.\n",
        "- ***However, complex output structures may still fail, so prompting and custom parsing function are still important in some cases.***\n",
        "\n",
        "Read more: [LangChain Docs – Structured Outputs](https://python.langchain.com/docs/concepts/structured_outputs/)\n"
      ],
      "metadata": {
        "id": "V9xRrjgy09pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pydantic schema\n",
        "\n",
        "# suppose that we want the output something like this :\n",
        "'''{'name': 'Alice',\n",
        " 'age': 21,\n",
        " 'scores': {'Math': 85, 'English': 92},\n",
        " 'extracurricular': ['Basketball', 'Drama Club']}'''\n",
        "\n",
        "# we can defined class (data fields) like this\n",
        "\n",
        "from typing import Dict, List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class DesiredOutput(BaseModel):\n",
        "    name: str = Field(description=\"Student's first name\")\n",
        "    age: int = Field(description=\"Age in years\")\n",
        "    extracurricular: List[str] = Field(description=\"List of activities/clubs\")\n",
        "\n",
        "    #subject_scores: Dict[str, int] = Field(description=\"Key = subject, Value = scores (as a JSON object)\")\n",
        "\n",
        "    # This line cause an error. / Complex Data Structure (uncomment if you want to test it)"
      ],
      "metadata": {
        "id": "DLSKUOVy0uN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap LLM so it returns a DesiredOutput object directly\n",
        "structured_llm = llm.with_structured_output(DesiredOutput)"
      ],
      "metadata": {
        "id": "LNMNByvN27fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are a helpful assistant.\n",
        "For the given student record, extract informations\n",
        "\n",
        "Student Record:\n",
        "Alice, 21 years old. Math = 85, English = 92. She joined Basketball and Drama Club.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Generate output\n",
        "results = structured_llm.invoke(prompt)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJc0JMrS3pld",
        "outputId": "c7a3cf6c-976c-4cb0-a798-cf7f9a31279c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DesiredOutput(name='Alice', age=21, extracurricular=['Basketball', 'Drama Club'])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.model_dump_json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fqArflod__Q4",
        "outputId": "49f2ddd9-a359-4e4c-f5c4-3f31a649d332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"name\":\"Alice\",\"age\":21,\"extracurricular\":[\"Basketball\",\"Drama Club\"]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Condition"
      ],
      "metadata": {
        "id": "BDGbHMMydyHV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boundary Condition Best Practices\n",
        "- **Don't know, don't guess**  \n",
        "  Instruct the model to answer *\"I don’t know\"* if the information is unknown or unverifiable.  \n",
        "  → Helps prevent the model from attempting to answer overly difficult or specific open-ended questions.  \n",
        "  > Note: This depends on the **use case** — but in scenarios where we *don’t want the model to attempt an uncertain answer*, this condition is very useful.\n",
        "\n",
        "- **Output Format Remarking**  \n",
        "  Explicitly remind the model about the required output format.  \n",
        "  → e.g., *\"Don’t give any additional explanation, just output [format] only.\"*"
      ],
      "metadata": {
        "id": "3xeHCngFhtAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Without boundary condition\n",
        "prompt = \"\"\"\n",
        "What are the details of the announcement from the Meteorological Department, ฉบับที่ 2/2568 เรื่อง 'มาตรการรับมือพายุฤดูร้อนก่อนกำหนด'?\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(\"With boundary condition:\\n\", ai_msg.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVMrB0dcd1ic",
        "outputId": "11a8bbac-8d8c-42c1-8b6c-9292be9c6444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With boundary condition:\n",
            " I cannot provide the details of the announcement from the Meteorological Department, ฉบับที่ 2/2568 เรื่อง 'มาตรการรับมือพายุฤดูร้อนก่อนกำหนด' because **it is dated for the year 2568 (2025), which has not yet occurred.**\n",
            "\n",
            "As an AI, my knowledge base is current up to my last training update (typically early 2023 for public models), and I do not have access to future announcements or real-time, future-dated information.\n",
            "\n",
            "**What such an announcement would typically cover (based on past patterns):**\n",
            "\n",
            "If and when the Meteorological Department issues an announcement like this in 2025, it would likely include:\n",
            "\n",
            "1.  **Warning of Specific Weather Phenomena:** Details about the expected characteristics of the early summer storms, such as:\n",
            "    *   Thunderstorms (พายุฝนฟ้าคะนอง)\n",
            "    *   Strong winds (ลมกระโชกแรง)\n",
            "    *   Hail (ลูกเห็บ)\n",
            "    *   Heavy rainfall (ฝนตกหนัก)\n",
            "    *   Lightning (ฟ้าผ่า)\n",
            "\n",
            "2.  **Affected Areas:** Specific provinces or regions that are expected to be impacted by these storms.\n",
            "\n",
            "3.  **Timing:** The expected period during which these conditions are likely to occur.\n",
            "\n",
            "4.  **Causes:** A brief explanation of the meteorological conditions leading to the storms (e.g., high-pressure system from China clashing with hot, humid air).\n",
            "\n",
            "5.  **Recommendations/Measures for the Public:** Advice on how to prepare and stay safe, such as:\n",
            "    *   Staying indoors or in sturdy buildings.\n",
            "    *   Securing outdoor belongings (e.g., advertising signs, trees, loose objects).\n",
            "    *   Avoiding open areas, large trees, and unstable structures during storms.\n",
            "    *   Being aware of potential flash floods and landslides in vulnerable areas.\n",
            "    *   Farmers being advised to protect their crops.\n",
            "    *   Following official weather updates closely.\n",
            "\n",
            "6.  **Contact Information:** Reminders to contact emergency services if needed.\n",
            "\n",
            "**To get current and accurate information:**\n",
            "\n",
            "When it is 2025, or for any current weather warnings, you should always refer to the official sources:\n",
            "\n",
            "*   **Thai Meteorological Department (TMD) Website:** [www.tmd.go.th](http://www.tmd.go.th)\n",
            "*   **TMD Social Media Channels:** Their official Facebook page or other platforms.\n",
            "*   **Reliable News Outlets:** Major Thai news agencies that report directly from the TMD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: With boundary condition\n",
        "prompt = \"\"\"\n",
        "What are the details of the announcement from the Meteorological Department, ฉบับที่ 2/2568 เรื่อง 'มาตรการรับมือพายุฤดูร้อนก่อนกำหนด'?\n",
        "\n",
        "If the answer is not known or cannot be verified, just reply: `I don’t know`.\n",
        "\"\"\"\n",
        "\n",
        "ai_msg = llm.invoke(prompt)\n",
        "print(\"With boundary condition:\\n\", ai_msg.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFYUTpPeyR4v",
        "outputId": "c4bb450a-833a-46ec-912a-4d86ee705f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With boundary condition:\n",
            " I don’t know\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template\n",
        "\n",
        "Prompt templates offer several benefits:\n",
        "\n",
        "- **Consistency**: Ensure a consistent structure for your prompts across multiple interactions\n",
        "- **Efficiency**: Easily swap out variable content without rewriting the entire prompt\n",
        "- **Testability**: Quickly test different inputs and edge cases by changing only the variable portion\n",
        "- **Scalability***: Simplify prompt management as your application grows in complexity\n",
        "- **Version control**: Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs"
      ],
      "metadata": {
        "id": "UyIZT0fiz-x9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example: Prompt Template in a Loop (Task: Sentiment Analysis)\n",
        "\n",
        "Example Task: **Sentiment Analysis**\n",
        "\n",
        "We used a prompt template with the approach **“run in a loop + change only variables”**.  \n",
        "This demonstrates how prompt templates cover several benefits at once:\n",
        "\n",
        "- **Consistency**: Every iteration uses the same prompt structure.  \n",
        "- **Efficiency**: Only the variable `{text}` changes in each loop.  \n",
        "- **Testability**: Multiple inputs can be tested quickly by swapping variable values.  \n",
        "- **Scalability**: The same template can be applied to a larger dataset without modification.  \n",
        "- **Version Control**: Easily track prompt versions against results.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3R-tfOsrRG7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt"
      ],
      "metadata": {
        "id": "4ryOL6guq0C-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427fa3cb-03ae-4ba2-9aeb-7f8f9e1cbdb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-02 07:52:39--  https://github.com/neubig/anlp-code/raw/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt [following]\n",
            "--2025-09-02 07:52:39--  https://raw.githubusercontent.com/neubig/anlp-code/refs/heads/main/data/sst-sentiment-text-threeclass/dev.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122071 (119K) [text/plain]\n",
            "Saving to: ‘dev.txt’\n",
            "\n",
            "dev.txt             100%[===================>] 119.21K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-02 07:52:39 (4.62 MB/s) - ‘dev.txt’ saved [122071/122071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_xy_data(filename: str) -> tuple[list[str], list[int]]:\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            label, text = line.strip().split(' ||| ')\n",
        "            x_data.append(text)\n",
        "            y_data.append(int(label))\n",
        "    return x_data, y_data"
      ],
      "metadata": {
        "id": "fXa_FpBL6zt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = read_xy_data('dev.txt')\n",
        "x_test, y_test = x_test[:10], y_test[:10] # small size for quick testing"
      ],
      "metadata": {
        "id": "IbNrlgaWRVz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For sentiment analysis, we will be using the following prompt:\n",
        "\n",
        "```\n",
        "Analyse the sentiment of the following text: ```text```\n",
        "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
        "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
        "```\n",
        "LLMs nowaday usually have chain-of-thought baked in so they usually will output their reasoning before answering.\n",
        "\n",
        "- It is important to tell the model not to output their explanation by including `**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
        "`\n",
        "- Otherwise, it will not be easy to programmatically use the outputs.\n",
        "Alternatively, you can use structured outputs `(see table of contents -> Structured Output)` for ease of parsing."
      ],
      "metadata": {
        "id": "6EU6prW_oeTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Analyse the sentiment of the following text: ```{x_input}```\n",
        "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative.\n",
        "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\"\"\""
      ],
      "metadata": {
        "id": "y3wwc3vJiiJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "Py85PRxuXwjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for sent in tqdm(x_test):\n",
        "   try:\n",
        "      prompt_filled = prompt_template.format(x_input=sent)\n",
        "      print('prompt:', prompt_filled) # debugging\n",
        "      output_res = llm.invoke(prompt_filled).content.strip()\n",
        "      print('response:', output_res) # debugging\n",
        "      print('--'*20)\n",
        "      output.append(int(output_res))\n",
        "   except:\n",
        "      output.append(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6b2996688f1d4d5489d599d4b60690da",
            "d71ecbd6004e472fb8fe27c2a57d760d",
            "e0f6a975c7be4ad8a0484848947d5708",
            "6318d668cd2b4298b0efce15cd362947",
            "fa95103c489442b280795fa1f392cc00",
            "82949eb1c4fa46a38e208df8d448ffb2",
            "15c14180c0864717a2b26b63a4be66bd",
            "0bb0402d02aa4cf09cb52a684b84158d",
            "5255a2351637421399e74703ea559b4a",
            "b52cbf35ca14411998e6fef206ca2841",
            "70688c7193ad4240848cfba9dd89fe93"
          ]
        },
        "id": "QFFPVtwT9rjZ",
        "outputId": "74943d92-7935-471a-b358-7669b18c99f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b2996688f1d4d5489d599d4b60690da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: \n",
            "Analyse the sentiment of the following text: ```It 's a lovely film with lovely performances by Buy and Accorsi .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```No one goes unindicted here , which is probably for the best .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```And if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```A warm , funny , engaging film .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Uses sharp humor and insight into human nature to examine class conflict , adolescent yearning , the roots of friendship and sexual identity .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Half Submarine flick , Half Ghost Story , All in one criminally neglected film``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Entertains by providing good , lively company .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Dazzles with its fully-written characters , its determined stylishness -LRB- which always relates to characters and story -RRB- and Johnny Dankworth 's best soundtrack in years .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Visually imaginative , thematically instructive and thoroughly delightful , it takes us on a roller-coaster ride from innocence to experience without even a hint of that typical kiddie-flick sentimentality .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n",
            "prompt: \n",
            "Analyse the sentiment of the following text: ```Nothing 's at stake , just a twisty double-cross you can smell a mile away -- still , the derivative Nine Queens is lots of fun .``` \n",
            "if the sentiment is positive output '1', '0' for neutral, and '-1' for negative. \n",
            "**DO NOT OFFER ANY EXPLANATION JUST OUTPUT THE NUMBER**\n",
            "response: 1\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp7ZS8hKVRb8",
        "outputId": "9a599f7d-513e-4b95-f285-933e5d6b561c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional: Temperature Setting"
      ],
      "metadata": {
        "id": "_AryYrz0F-Pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Settings to keep in mind\n",
        "\n",
        "- Temperature is an important parameter to consider.\n",
        "  - Keep it low if you are looking for exact or deterministic answers.\n",
        "  - Keep it high if you are looking for more diverse or creative responses.\n",
        "\n",
        "> In all the previous examples, we only set up the LLM once, and the parameter was fixed as Temperature = 0\n",
        "\n",
        "This means every example so far was generated with a deterministic setting (no randomness)."
      ],
      "metadata": {
        "id": "oNWq0plMFcEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temperature Range for Gemini-2.5-flash : 0-2 (default 1)\n",
        "\n",
        ">Ref: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-flash"
      ],
      "metadata": {
        "id": "mJA6w0hAdyxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm_low_temp = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "1LscvX8fjVzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_high_temp = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=2,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "gx4NPLujeWZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_low_temp\n",
        "prompt = \"Write one slogan for a mobile banking application.\"\n",
        "for rnd in range(3):\n",
        "  try:\n",
        "    output_res = llm_low_temp.invoke(prompt).content.strip()\n",
        "    print(f\"Round {rnd+1} | response:\", output_res)\n",
        "  except Exception as e:\n",
        "    print(f\"Round {rnd+1} | Error:\", e)\n",
        "\n",
        "  print(\"--\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbra6aNZgtM3",
        "outputId": "18711d09-cd1c-4bf1-e292-b711250574ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1 | response: **Tap into your finances.**\n",
            "------------------------------------------------------------\n",
            "Round 2 | response: **Your bank, in your hand.**\n",
            "------------------------------------------------------------\n",
            "Round 3 | response: **Your bank, in your hand.**\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm_high_temp\n",
        "prompt = \"Write one slogan for a mobile banking application.\"\n",
        "for rnd in range(3):\n",
        "  try:\n",
        "    output_res = llm_high_temp.invoke(prompt).content.strip()\n",
        "    print(f\"Round {rnd+1} | response:\", output_res)\n",
        "  except Exception as e:\n",
        "    print(f\"Round {rnd+1} | Error:\", e)\n",
        "\n",
        "  print(\"--\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAlpPN-nhd4w",
        "outputId": "254d32e5-1bbc-465c-c324-28627a4c0ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1 | response: **Financial freedom, in your pocket.**\n",
            "------------------------------------------------------------\n",
            "Round 2 | response: **Your Bank, On Your Terms.**\n",
            "------------------------------------------------------------\n",
            "Round 3 | response: **Your Money. Anytime. Anywhere.**\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "\n",
        "- Low temp → Reliable, consistent outputs. Useful for classification, extraction, or when you want reproducibility.\n",
        "- High temp → Diverse, creative slogans. Useful for brainstorming, ideation, or when multiple fresh options are desired."
      ],
      "metadata": {
        "id": "jp0VKZZVhzsD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CEVHTAIMh1OU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}